{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "867d6d9d",
   "metadata": {},
   "source": [
    "# 2023 MƒÅtai Intern fMRI workshop\n",
    "By Josh McGeown, PhD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddba3f1",
   "metadata": {},
   "source": [
    "<img src=\"./supp/rubiks.jpg\" \n",
    "     align=\"center\" \n",
    "     width=\"300\"\n",
    "     height=\"300\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9831959",
   "metadata": {},
   "source": [
    "### What is a voxel?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426fedb0",
   "metadata": {},
   "source": [
    "### What is a volume?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdb4719",
   "metadata": {},
   "source": [
    "### What is the BOLD response?\n",
    "\n",
    "__B__lood <br>\n",
    "__O__xygen <br>\n",
    "__L__evel <br>\n",
    "__D__ependent <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b41cce",
   "metadata": {},
   "source": [
    "<img src=\"./supp/bold.png\" \n",
    "     align=\"center\" \n",
    "     width=\"600\"\n",
    "     height=\"600\" />\n",
    "     \n",
    "Image credit: Andy's Brain Book https://andysbrainbook.readthedocs.io/en/latest/_images/BOLD_Response.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c7b2cd",
   "metadata": {},
   "source": [
    "## What is fMRI?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b71c61a",
   "metadata": {},
   "source": [
    "See this simple explanation: https://www.youtube.com/watch?v=4UOeBM5BwdY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54f5a98",
   "metadata": {},
   "source": [
    "## Task-based fMRI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c53ba6",
   "metadata": {},
   "source": [
    "<img src=\"./supp/task_design.png\" \n",
    "     align=\"center\" \n",
    "     width=\"400\"\n",
    "     height=\"400\" />\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abb9a00",
   "metadata": {},
   "source": [
    "<img src=\"./supp/design_hrf.png\" \n",
    "     align=\"center\" \n",
    "     width=\"600\"\n",
    "     height=\"600\" />\n",
    "     \n",
    "Image credit: FSL Introduction to Task FMRI Experiments and Analysis (https://www.youtube.com/watch?v=y7wtbMl3y4E)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7353e9dd",
   "metadata": {},
   "source": [
    "## Resting-state fMRI and functional connectivity\n",
    "\n",
    "Neurosynth example: https://www.neurosynth.org/analyses/terms/default%20mode/\n",
    "\n",
    "<img src=\"./supp/fMRI.png\" \n",
    "     align=\"center\" \n",
    "     width=\"800\"\n",
    "     height=\"800\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe3faa4",
   "metadata": {},
   "source": [
    "### A note on preprocessing\n",
    "\n",
    "<img src=\"./supp/fmriprep.png\" \n",
    "     align=\"center\" \n",
    "     width=\"800\"\n",
    "     height=\"800\" />\n",
    "     \n",
    "Image credit: fMRIPREP https://fmriprep.org/en/stable/_static/OHBM2018-poster.png\n",
    "     \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447f3612",
   "metadata": {},
   "source": [
    "# Time to work with some data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fb927b",
   "metadata": {},
   "source": [
    "### Load the tools (aka libraries) we will need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f71ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython\n",
    "\n",
    "import nibabel as nib\n",
    "from nilearn import datasets\n",
    "from nilearn import input_data\n",
    "from nilearn import plotting\n",
    "from nilearn import image\n",
    "from nilearn.input_data import NiftiMapsMasker\n",
    "from nilearn.input_data import NiftiSpheresMasker\n",
    "\n",
    "from scipy import stats\n",
    "from mne.stats import fdr_correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e79924b",
   "metadata": {},
   "source": [
    "### Figure out where we are on our computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056c7db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"/nesi/nobackup/uoa03264/Workshop/fmri\"\n",
    "print(datadir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3908c0e7",
   "metadata": {},
   "source": [
    "### Define scan id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce67a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort = \"rugby\"\n",
    "subject = 1\n",
    "session = \"b\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5aa4eef",
   "metadata": {},
   "source": [
    "### Load resting-state fMRI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c117f6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_file = (\n",
    "    datadir\n",
    "    + f\"/sub-{cohort}{subject}_ses-{session}_task-rest_run-001_space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz\"\n",
    ")\n",
    "\n",
    "# print basic information on the dataset\n",
    "print(\"First subject functional nifti image (4D) is at:\", func_file)  # 4D data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca725995",
   "metadata": {},
   "source": [
    "### Load raw echo-planar imaging (EPI) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45293068",
   "metadata": {},
   "outputs": [],
   "source": [
    "epi_img = nib.load(func_file)\n",
    "epi_img_data = epi_img.get_fdata()\n",
    "print(epi_img_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1900322d",
   "metadata": {},
   "source": [
    "### This means each \"rubiks cube\" is 97 voxels _wide_, 97 voxels _tall_, and 115 voxels _deep_ and we have __200__ images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975945e1",
   "metadata": {},
   "source": [
    "### Plot mean of raw EPI image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f5ce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_epi = image.mean_img(epi_img)\n",
    "plotting.plot_epi(mean_epi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12d34d5",
   "metadata": {},
   "source": [
    "### Time to apply a mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd46b37b",
   "metadata": {},
   "source": [
    "<img src=\"./supp/masking.jpg\" \n",
    "     align=\"center\" \n",
    "     width=\"500\"\n",
    "     height=\"500\" />\n",
    "     \n",
    "Image credit to Elizabeth DuPre from _An introduction to nilearn_ https://emdupre.github.io/nha2020-nilearn/01-data-structures.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ab9113",
   "metadata": {},
   "source": [
    "### Load image mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a62c4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_file = (\n",
    "    datadir\n",
    "    + f\"/sub-{cohort}{subject}_ses-{session}_task-rest_run-001_space-MNI152NLin2009cAsym_res-2_desc-brain_mask.nii.gz\"\n",
    ")\n",
    "\n",
    "mask = nib.load(mask_file)\n",
    "plotting.plot_img(mask, black_bg=True)\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc70478f",
   "metadata": {},
   "source": [
    "### Plot mask over averaged raw EPI image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aef1230",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_roi(mask, mean_epi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd0a6be",
   "metadata": {},
   "source": [
    "## Placing a seed to inspect BOLD signal within a single voxel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1902ef",
   "metadata": {},
   "source": [
    "### Load parameters we will need to clean our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2251107e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_time = 1.5  # Repetition time of scan\n",
    "hp = 0.01  # High pass filter\n",
    "lp = 0.1  # Low pass filter\n",
    "fwhm = 6  # Full width half maximum smoothing filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf5f8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = [(-0.15, 51.42, 7.58)]\n",
    "x, y, z = [0, 51, 8]\n",
    "\n",
    "display = plotting.plot_anat(cut_coords=coords[0], black_bg=True, draw_cross=False)\n",
    "display.add_markers(marker_coords=coords, marker_color=\"yellow\", marker_size=30)\n",
    "display.add_markers(marker_coords=coords, marker_color=\"yellow\", marker_size=30)\n",
    "\n",
    "seed_mask = input_data.NiftiSpheresMasker(\n",
    "    coords,\n",
    "    radius=0,\n",
    "    detrend=False,\n",
    "    standardize=False,\n",
    "    t_r=rep_time,\n",
    "    memory=\"nilearn_cache\",\n",
    "    memory_level=1,\n",
    "    verbose=0,\n",
    "    mask_img=mask,\n",
    ")\n",
    "\n",
    "seed_ts = seed_mask.fit_transform(func_file)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "plt.plot(seed_ts, \"b\", alpha=0.7)\n",
    "plt.legend([\"Raw\"], loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9404e75f",
   "metadata": {},
   "source": [
    "## Signal-to-Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d15708",
   "metadata": {},
   "source": [
    "Things that can introduce noise in MRI: <br>\n",
    "- Items interfering with magnetic field i.e. braces, metal implants\n",
    "- Electromagnetic properties of other equipment nearby\n",
    "- Gross motion\n",
    "- Physiological motion (breathing/heart rate)\n",
    "- Properties of tissues we aren't trying to study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624540ad",
   "metadata": {},
   "source": [
    "<img src=\"./supp/snr.png\" \n",
    "     align=\"left\" \n",
    "     width=\"8000\"\n",
    "     height=\"8000\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae148ae",
   "metadata": {},
   "source": [
    "### Load confounding (aka nuisance) data that contributes noise to our signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8356a230",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confound_file = (\n",
    "    datadir\n",
    "    + f\"/sub-{cohort}{subject}_ses-{session}_task-rest_run-001_desc-confounds_timeseries.tsv\"\n",
    ")\n",
    "\n",
    "confounds = pd.read_csv(confound_file, sep=\"\\t\")\n",
    "confounds = confounds.iloc[:, :-1]\n",
    "IPython.display(confounds.head())\n",
    "\n",
    "confounds_matrix = confounds.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affbb48c",
   "metadata": {},
   "source": [
    "<img src=\"./supp/6dof.png\" \n",
    "     align=\"center\" \n",
    "     width=\"800\"\n",
    "     height=\"400\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f62f24",
   "metadata": {},
   "source": [
    "## Let's look at how to maximize the Signal-to-Noise Ratio\n",
    "### First we detrend, standardize, regress confounds out of the data\n",
    "We do this because we are more interested in __patterns__ of activity than __absolute__ values which can vary voxel to voxel and across session/people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f95396e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_mask = input_data.NiftiSpheresMasker(\n",
    "    coords,\n",
    "    radius=0,\n",
    "    detrend=True,  # Changed this setting to True\n",
    "    standardize=True,  # Changed this setting to True\n",
    "    t_r=rep_time,\n",
    "    memory=\"nilearn_cache\",\n",
    "    memory_level=1,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "seed_ts_ds_c = seed_mask.fit_transform(func_file, confounds=confounds_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b296089a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=3, figsize=(12, 12))\n",
    "\n",
    "ax[0].plot(seed_ts, \"b\", alpha=0.7)\n",
    "ax[0].legend([\"Raw\"], fontsize=20)\n",
    "\n",
    "ax[1].plot(seed_ts, \"b\", alpha=0.7, linewidth=3)\n",
    "ax[1].plot(seed_ts_ds_c, \"r\", linewidth=3)\n",
    "ax[1].legend([\"Raw\", \"Detrend + Standardize + Confound regression\"], fontsize=20)\n",
    "\n",
    "ax[2].plot(seed_ts_ds_c, \"r\")\n",
    "ax[2].legend([\"Detrend + Standardize + Confound regression\"], fontsize=20)\n",
    "\n",
    "ax[2].set_xlabel(\"Samples (time)\", fontweight=\"bold\", fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a3f022",
   "metadata": {},
   "source": [
    "### This looks better but we still need to filter our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514b497e",
   "metadata": {},
   "source": [
    "### Filter signal using a bandpass filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cd0226",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_mask = input_data.NiftiSpheresMasker(\n",
    "    coords,\n",
    "    radius=0,\n",
    "    detrend=True,\n",
    "    standardize=True,\n",
    "    high_pass=hp,  # Define the high frequency limit of bandpass filter\n",
    "    low_pass=lp,  # Define the low frequency limit of bandpass filter\n",
    "    t_r=rep_time,\n",
    "    memory=\"nilearn_cache\",\n",
    "    memory_level=1,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "seed_ts_ds_c_f = seed_mask.fit_transform(func_file, confounds=confounds_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710d96cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, figsize=(15, 15))\n",
    "\n",
    "ax[0].plot(seed_ts_ds_c, \"k\", alpha=0.66)\n",
    "ax[0].legend([\"Detrend + Standardize + Confound regression\"], fontsize=20)\n",
    "ax[1].plot(seed_ts_ds_c_f, \"magenta\")\n",
    "ax[1].legend([\"Detrend + Standardize + Confound regression + Filtered\"], fontsize=20)\n",
    "\n",
    "ax[1].set_xlabel(\"Samples (time)\", fontweight=\"bold\", fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fb9833",
   "metadata": {},
   "source": [
    "## Exploring functional connectivity within brain networks\n",
    "Atlases allow us to easily and efficiently identify different regions of interest within the brain for our analysis\n",
    "\n",
    "### Load the MSDL atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b51ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas = datasets.fetch_atlas_msdl()\n",
    "atlas_filename = atlas[\"maps\"]\n",
    "\n",
    "atlas_df = pd.DataFrame.from_dict(atlas)\n",
    "IPython.display(atlas_df.iloc[:, 1:-1].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4149a0",
   "metadata": {},
   "source": [
    "__These are the 16 networks available within the MSDL atlas:__ <br>\n",
    "- 'Ant IPS' \n",
    "- 'Aud' \n",
    "- 'Basal' \n",
    "- 'Cereb', \n",
    "- 'Cing-Ins'\n",
    "- 'D Att'\n",
    "- 'DMN'\n",
    "- 'Dors PCC' \n",
    "- 'L V Att'\n",
    "- 'Language' \n",
    "- 'Motor'\n",
    "- 'Occ post'\n",
    "- 'R V Att'\n",
    "- 'Salience'\n",
    "- 'Striate'\n",
    "- 'Temporal' \n",
    "- 'Vis Sec' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085e0c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate blank dictionary of 16 unique msdl_networks\n",
    "keys = list(set(atlas[\"networks\"]))\n",
    "msdl_networks = dict.fromkeys(keys)\n",
    "for key in msdl_networks.keys():\n",
    "    msdl_networks[key] = []\n",
    "\n",
    "# Populate dictionary with indexes of anatomical seeds that correspond to functional networks\n",
    "for i in range(0, len(atlas[\"networks\"])):\n",
    "    temp = atlas[\"networks\"][i]\n",
    "    if temp in msdl_networks.keys():\n",
    "        msdl_networks[temp].append(i)\n",
    "    else:\n",
    "        msdl_networks[temp] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9eedf4",
   "metadata": {},
   "source": [
    "### Plot map for all networks within MSDL atlas individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65370498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View probabilistic map for all networks within atlas individually\n",
    "for i in keys:\n",
    "    network_nodes = image.index_img(atlas_filename, msdl_networks[i])\n",
    "    atlas_plot = plotting.plot_prob_atlas(\n",
    "        network_nodes,\n",
    "        cut_coords=6,\n",
    "        display_mode=\"z\",\n",
    "        title=\"{ntwk} nodes in MSDL atlas\".format(ntwk=i),\n",
    "        black_bg=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087f530c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auditory_L = [(-53.28, -8.88, 32.36)]\n",
    "auditory_R= [(53.47, -6.49, 27.52)]\n",
    "motor = [(-1.48, -27.93, 61.5)]\n",
    "\n",
    "seed_list = [auditory_L, auditory_R, motor]\n",
    "\n",
    "voxel_ts_array = np.empty((200, len(seed_list))\n",
    "\n",
    "for i, seed in enumerate(seed_list):\n",
    "    seed_mask = input_data.NiftiSpheresMasker(seed,\n",
    "                                              radius=10, \n",
    "                                              detrend=True, \n",
    "                                              standardize=True, \n",
    "                                              low_pass=lp, \n",
    "                                              high_pass=hp,\n",
    "                                              t_r=rep_time,\n",
    "                                              memory='nilearn_cache',\n",
    "                                              memory_level=1,\n",
    "                                              verbose=0)\n",
    "\n",
    "    voxel_ts_array[:, i] = seed_mask.fit_transform(func_file, confounds=confounds_matrix)\n",
    "    \n",
    "print(voxel_ts_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb37f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.plot(voxel_ts_array[:, 1], \"b--\", alpha=0.3, linewidth=2)\n",
    "plt.plot(voxel_ts_array[:, 2], \"g--\", alpha=0.7, linewidth=2)\n",
    "plt.plot(voxel_ts_array[:, 0], \"r\", alpha=0.8, linewidth=3.5)\n",
    "plt.legend([\"Right auditory\", \"Motor\", \"Left auditory\"], loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef1fdab",
   "metadata": {},
   "source": [
    "### Plot our example network of interest - Default Mode Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04032f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define single network and plot probabilistic map from atlas\n",
    "ntwk = \"DMN\"  # Functional network of interest\n",
    "\n",
    "# Create fig object to plot atlas and subject bold signal together\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "network_nodes = image.index_img(atlas_filename, msdl_networks[ntwk])  # define nodes\n",
    "print(network_nodes.shape)\n",
    "\n",
    "atlas_plot = plotting.plot_prob_atlas(\n",
    "    network_nodes,\n",
    "    cut_coords=6,\n",
    "    display_mode=\"z\",\n",
    "    title=\"{ntwk} nodes in MSDL atlas\".format(ntwk=ntwk),\n",
    "    black_bg=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843a1420",
   "metadata": {},
   "source": [
    "### Generate a mask for the nodes of the DMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885c85ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_masker = NiftiMapsMasker(\n",
    "    maps_img=network_nodes,\n",
    "    smoothing_fwhm=fwhm,\n",
    "    standardize=True,\n",
    "    detrend=True,\n",
    "    low_pass=lp,\n",
    "    high_pass=hp,\n",
    "    t_r=rep_time,\n",
    "    memory=\"nilearn_cache\",\n",
    "    memory_level=1,\n",
    "    verbose=0,\n",
    "    mask_img=mask,\n",
    ")\n",
    "\n",
    "# time series for network of interest\n",
    "network_time_series = atlas_masker.fit_transform(func_file, confounds=confounds_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37a1eb8",
   "metadata": {},
   "source": [
    "### Mask the whole brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c207d8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_masker = input_data.NiftiMasker(\n",
    "    smoothing_fwhm=fwhm,\n",
    "    detrend=True,\n",
    "    standardize=True,\n",
    "    low_pass=lp,\n",
    "    high_pass=hp,\n",
    "    t_r=rep_time,\n",
    "    memory=\"nilearn_cache\",\n",
    "    memory_level=1,\n",
    "    verbose=0,\n",
    "    mask_img=mask,\n",
    ")\n",
    "\n",
    "brain_time_series = brain_masker.fit_transform(func_file, confounds=confounds_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447e4e4c",
   "metadata": {},
   "source": [
    "### Look at what the masking steps have done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78e5c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Seed time series shape: (%s, %s)\" % network_time_series.shape)\n",
    "print(\"Brain time series shape: (%s, %s)\" % brain_time_series.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba7bf80",
   "metadata": {},
   "source": [
    "### Calculate correlation between BOLD signal in seeds of interest vs every other voxel in the brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93b3e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlate network nodes of interest against brain mask time series\n",
    "network_to_voxel_correlations = (\n",
    "    np.dot(brain_time_series.T, network_time_series) / network_time_series.shape[0]\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Network-to-voxel correlation shape: (%s, %s)\" % network_to_voxel_correlations.shape\n",
    ")\n",
    "print(\n",
    "    \"Network-to-voxel correlation: min = %.3f; max = %.3f\"\n",
    "    % (network_to_voxel_correlations.min(), network_to_voxel_correlations.max())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982778c7",
   "metadata": {},
   "source": [
    "### Plot voxels where BOLD signal correlates with the BOLD signal from our seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0a732d",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_to_voxel_correlations_img = brain_masker.inverse_transform(\n",
    "    network_to_voxel_correlations.mean(axis=1).T\n",
    ")\n",
    "\n",
    "display = plotting.plot_stat_map(\n",
    "    network_to_voxel_correlations_img,\n",
    "    threshold=0.1,\n",
    "    cut_coords=[30],\n",
    "    display_mode=\"z\",\n",
    "    vmax=1,\n",
    "    title=\"Voxels where the BOLD signal is correlated to the signal in our seed\",\n",
    "    cmap=\"green_transparent\",\n",
    "    colorbar=False,\n",
    "    black_bg=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199833ce",
   "metadata": {},
   "source": [
    "## Multiple comparisons\n",
    "- p-value of 0.05 means we are willing to accept a false positive 5% of the time <br>\n",
    "- But this assumes we are only conducting one test <br>\n",
    "- If we conduct multiple tests on related data... say 20 tests ... we would expect at least one of the tests to be a fall positive 1/20 = 5% <br>\n",
    "- In some studies we account for this by shrinking the p-value based on the number of tests i.e. 0.05/20 = 0.0025 <br>\n",
    "- Now a p-value has to be < 0.0025 to be \"significant\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c5860f",
   "metadata": {},
   "source": [
    "But in imaging we have a problem of big numbers... in the case of the data we are working with we have 240185 correlations against our seed (the total number of voxels we are evaluating)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a10853",
   "metadata": {},
   "source": [
    "Based on our typical false positive rate we would expect at least 12000 voxels will show a relationship with our seed that is purely random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d18570d",
   "metadata": {},
   "source": [
    "To correct for this we would have to divide our p-value by 240185 (the total number of voxels we are evaluting) which would make our new p-value: 0.0000002080"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b12a6ba",
   "metadata": {},
   "source": [
    "Instead we account for this problem using a technique called the __False Discovery Rate (FDR)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffe88d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdr_alpha = 0.01  # False detection rate p-value threshold\n",
    "\n",
    "# calculate t statistics from network_to_voxel_correlations\n",
    "t_vals = (network_to_voxel_correlations * np.sqrt(epi_img.shape[3] - 2)) / np.sqrt(\n",
    "    1 - network_to_voxel_correlations**2\n",
    ")\n",
    "\n",
    "# convert t statistics to p values\n",
    "p_vals = stats.t.sf(np.abs(t_vals), df=epi_img.shape[3] - 2) * 2\n",
    "\n",
    "# implement mne library fdr_correction\n",
    "reject_fdr, pval_fdr = fdr_correction(p_vals, alpha=fdr_alpha, method=\"indep\")\n",
    "reject_fdr = reject_fdr * 1  # convert boolean series to binary\n",
    "\n",
    "network_to_voxel_correlations_corrected = network_to_voxel_correlations * reject_fdr\n",
    "\n",
    "network_to_voxel_correlations_corrected_img = brain_masker.inverse_transform(\n",
    "    network_to_voxel_correlations_corrected.mean(axis=1).T\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19200dab",
   "metadata": {},
   "source": [
    "### Plot to contrast results pre/after FDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f40a5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = plotting.plot_stat_map(\n",
    "    network_to_voxel_correlations_img,\n",
    "    threshold=0.1,\n",
    "    cut_coords=[30],\n",
    "    display_mode=\"z\",\n",
    "    vmax=1,\n",
    "    title=\"Everything green is a False Positive\",\n",
    "    cmap=\"green_transparent\",\n",
    "    colorbar=False,\n",
    "    black_bg=True,\n",
    ")\n",
    "\n",
    "display.add_overlay(\n",
    "    network_to_voxel_correlations_corrected_img, threshold=0.1, cmap=\"binary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f18554",
   "metadata": {},
   "source": [
    "### Visualise unthresholded image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fca5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 20))\n",
    "\n",
    "display = plotting.plot_stat_map(\n",
    "    network_to_voxel_correlations_corrected_img,\n",
    "    threshold=0,\n",
    "    cut_coords=[-16, 0, 16, 30, 44, 58],\n",
    "    display_mode=\"z\",\n",
    "    vmax=1,\n",
    "    title=f\"Network-to-voxel correlation - {ntwk} Matai test {subject}\",\n",
    "    cmap=\"magma\",\n",
    "    black_bg=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d35e70",
   "metadata": {},
   "source": [
    "## Visualise thresholded image against DMN nodes from MSDL atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837533bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.3\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, figsize=(20, 10))\n",
    "\n",
    "atlas_plot = plotting.plot_prob_atlas(\n",
    "    network_nodes,\n",
    "    cut_coords=6,\n",
    "    display_mode=\"z\",\n",
    "    title=f\"{ntwk} nodes in MSDL atlas\",\n",
    "    axes=ax[0],\n",
    "    black_bg=True,\n",
    ")\n",
    "\n",
    "display = plotting.plot_stat_map(\n",
    "    network_to_voxel_correlations_corrected_img,\n",
    "    threshold=thresh,\n",
    "    cut_coords=[-16, 0, 16, 30, 44, 58],\n",
    "    display_mode=\"z\",\n",
    "    vmax=1,\n",
    "    title=f\"Network-to-voxel correlation - {ntwk} Matai test {subject}\",\n",
    "    cmap=\"magma\",\n",
    "    axes=ax[1],\n",
    "    black_bg=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e93a26",
   "metadata": {},
   "source": [
    "## Other options:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9011bc5",
   "metadata": {},
   "source": [
    "### Plotting on a surface\n",
    "\n",
    "<img src=\"./supp/fmri_dmn_surf.png\" \n",
    "     align=\"center\" \n",
    "     width=\"500\"\n",
    "     height=\"500\" />\n",
    "     \n",
    "### Connectomes\n",
    "\n",
    "https://nilearn.github.io/stable/auto_examples/03_connectivity/plot_atlas_comparison.html#sphx-glr-auto-examples-03-connectivity-plot-atlas-comparison-py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matai_training_2023",
   "language": "python",
   "name": "matai_training_2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
